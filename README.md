
# üß† Suicide Prediction and Mental Health

Proyecto de Ciencia de Datos y MLOps para analizar y predecir la **tasa de suicidios por 100k habitantes** a partir de datos hist√≥ricos de la OMS (1979‚Äì2016).

Incluye:

* üìä **EDA (Exploratory Data Analysis)** con visualizaciones (mapas, rankings, evoluci√≥n temporal).
* ü§ñ **Modelado predictivo** con Random Forest, XGBoost y Gradient Boosting.
* ‚öôÔ∏è **Optimizaci√≥n de hiperpar√°metros** y evaluaci√≥n con curvas de aprendizaje y m√©tricas.
* üîç **Interpretabilidad** con Feature Importances y SHAP.
* üåê **API en FastAPI** para servir el modelo.
* üéõ **UI en Streamlit** para probar predicciones de forma interactiva.
* üê≥ **Docker Compose** para levantar todo el stack (API + UI).

---

## üìÇ Estructura del proyecto

```
suicide-prediction-and-mental-health/
‚îÇ
‚îú‚îÄ‚îÄ data/                  # Datos raw y procesados
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ
‚îú‚îÄ‚îÄ notebooks/             # Notebooks de an√°lisis y modelado
‚îÇ   ‚îî‚îÄ‚îÄ 02_modelado.ipynb
‚îÇ
‚îú‚îÄ‚îÄ models/                # Modelos entrenados (.joblib)
‚îÇ
‚îú‚îÄ‚îÄ src/                   # C√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ make_dataset.py    # Limpieza y guardado del dataset
‚îÇ   ‚îú‚îÄ‚îÄ train_pipeline.py  # Entrenamiento y pipeline
‚îÇ   ‚îú‚îÄ‚îÄ predict_cli.py     # Predicci√≥n desde terminal
‚îÇ   ‚îú‚îÄ‚îÄ app.py             # API con FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ streamlit_app.py   # UI standalone
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app_api.py # UI que consume la API
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt       # Dependencias base
‚îú‚îÄ‚îÄ requirements-api.txt   # Dependencias para API/UI
‚îú‚îÄ‚îÄ Dockerfile             # Imagen de API
‚îú‚îÄ‚îÄ Dockerfile.streamlit   # Imagen de UI
‚îú‚îÄ‚îÄ docker-compose.yml     # Orquestaci√≥n
‚îî‚îÄ‚îÄ README.md              # Este archivo
```

---

## üìä Exploratory Data Analysis (EDA)

* Dataset con **43776 filas** y 6 columnas: `country`, `year`, `sex`, `age`, `suicides_no`, `population`.
* Visualizaciones principales:

  * Mapa mundial de tasas promedio (1979‚Äì2016).
  * Top/Bottom 10 pa√≠ses.
  * Evoluci√≥n temporal de pa√≠ses seleccionados.
* Hallazgos:

  * Europa del Este lidera con las tasas m√°s altas (Hungr√≠a, Lituania, Rusia).
  * Am√©rica Latina muestra valores moderados (Uruguay \~18, Argentina \~10, Brasil \~6).
  * Algunos pa√≠ses con tasas bajas probablemente reflejan **falta de datos**.

---

## ü§ñ Modelado

Se probaron 3 algoritmos:

| Modelo               | MAE  | RMSE | R¬≤    |
| -------------------- | ---- | ---- | ----- |
| Random Forest        | 2.70 | 6.56 | 0.887 |
| HistGradientBoosting | 4.73 | 8.39 | 0.815 |
| XGBoost              | 4.29 | 7.52 | 0.852 |

üëâ **Random Forest fue el mejor modelo.**

### üîß Tuning

* `RandomSearchCV` mejor√≥ el equilibrio train/test, reduciendo overfitting.
* Curvas de aprendizaje mostraron alta varianza en datos peque√±os, pero buena generalizaci√≥n en datos completos.

---

## üîç Interpretabilidad

* Variables m√°s importantes:

  * `sex` (los hombres muestran mayor riesgo).
  * `year` (tendencia temporal).
  * Rango etario (m√°s incidencia en adultos j√≥venes y mayores).
  * Pa√≠ses del Este europeo.


---

## üåê API con FastAPI

Endpoints:

* `GET /` ‚Üí mensaje de bienvenida.
* `POST /predict` ‚Üí recibe JSON con `country, year, sex, age` y devuelve predicci√≥n.

Ejemplo request:

```json
{
  "records": [
    {"country": "Argentina", "year": 2016, "sex": "male", "age": "25-34 years"}
  ]
}
```

Ejemplo response:

```json
{
  "predictions": [12.45]
}
```

Correr localmente:

```bash
uvicorn src.app:app --reload --port 8000
```

Docs: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## üéõ UI con Streamlit

Standalone:

```bash
streamlit run src/streamlit_app.py
```

Via API:

```bash
streamlit run src/streamlit_app_api.py
```

Disponible en [http://localhost:8501](http://localhost:8501)

---

## üê≥ Docker Compose

Levantar todo el stack:

```bash
docker compose up --build
```

Servicios:

* API ‚Üí [http://localhost:8000/docs](http://localhost:8000/docs)
* UI  ‚Üí [http://localhost:8501](http://localhost:8501)


Exacto üëå ‚Äî es **muy buena pr√°ctica** documentar eso en tu repo, para que cualquiera que lo clone entienda por qu√© no encuentra los `.joblib` o datasets pesados.

Lo ideal es armar una secci√≥n en el **README.md**, por ejemplo as√≠:

---

### üì¶ Datos y modelos

> ‚ö†Ô∏è **Nota importante:**
> Algunos archivos no se incluyen en este repositorio porque superan el l√≠mite de tama√±o de GitHub (100 MB).
> En particular:
>
> * `models/rf_pipeline.joblib` (\~200 MB)
> * `notebooks/models/rf_final_tuned.joblib` (\~165 MB)
>
> Estos artefactos se pueden **re-generar** localmente ejecutando:
>
> ```bash
> python src/train_pipeline.py
> ```
>
> Esto entrenar√° el modelo Random Forest con los hiperpar√°metros optimizados y lo guardar√° en `models/`.
